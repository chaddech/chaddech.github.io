<HTML>

  <HEAD>
  <link rel="stylesheet" href="home.css" type="text/css">
  <TITLE> Chad DeChant </TITLE>
  </HEAD>

  <BODY>
  
<div id="frame">
  <div id="me">
  <H1> Chad DeChant </H1>
  <table cellspacing=0 cellpadding=0 style="color: black; font-size: 100%">
  <tr><td>c</td><td>h</td><td>a</td><td>d</td><td>.</td><td>d</td><td>e</td><td>c</td><td>h</td><td>a</td><td>n</td><td>t</td>
  <td>@</td><td>c</td><td>o</td><td>l</td><td>u</td><td>m</td><td>b</td><td>i</td><td>a</td><td>.</td><td>e</td><td>d</td><td>u</td>
  </tr>
  </table>

  <table>
  <p>
  <tr><td align=right>Twitter: </td><td><a href="https://twitter.com/chaddechant">@chaddechant</a></td></tr>
  </table>
  <table>
  <p>
  <tr><td align=right></td><td><a href="https://scholar.google.com/citations?user=vZbAfPIAAAAJ&hl=en">Google Scholar</a>
</td></tr>
  </table>

  <p>
  <table>
  <tr><td>PhD, Computer Science</td></tr>
  <tr><td>Columbia University</td></tr>
  <tr><td>  </td></tr>
  <tr><td>  </td></tr>
  <tr><td>  </td></tr>

  <tr><td>MA, Government, Institute for International Law and Politics</td></tr>
  <tr><td>Georgetown University</td></tr>
  <tr><td>  </td></tr>
  <tr><td>  </td></tr>
  <tr><td>  </td></tr>

  <tr><td>BA, Philosophy</td></tr>
  <tr><td>Georgetown University</td></tr>

  <tr><td>  </td></tr>
  <tr><td>  </td></tr>

  <tr><td>I received a PhD in Computer Science from Columbia in Spring 2025, advised by Daniel Bauer. My goal is to apply cognitive science research to make AI safe, reliable, and interpretable. </td></tr>
  
  <tr><td>My dissertation was on enabling robots to remember and report on their past actions in natural language through summaries and question answering. I believe that this ability is an essential one both for training robots and other agents to better understand their environments and for ensuring safe and understandable agent behavior.  </td></tr>
  
  <tr><td> I have also worked on artificial metacognition (i.e. thinking about thinking, especially knowing what we know), learning word representations in the order a child learns words, improving robotic grasping techniques by learning to 'imagine' parts of objects that are hidden, and detecting crop disease from field imagery. </td></tr>

  <tr><td> I created and taught a course for Columbia undergraduates on AI Safety, Ethics, and Policy.</td></tr>

  <tr><td> <b>I am on the job market, looking for postdoc or research scientist positions.</b></td></tr>


  </table>
  </div>



  <div id="picture">
  <a href="IMG_0104.jpg">
  <IMG SRC="IMG_0104.jpg" height="450" alt="Large picture of Chad DeChant">
  </a>
  </div>

  <div id="epilogue">
  <HR>
  </div>

  <div id="class">
  <H3>Selected Publications</H3>
    <ul>
  <dl>

<dt><i>Episodic memory in AI agents poses risks that should be studied and mitigated</i><br />Chad DeChant
<br>Conference on Secure and Trustworthy Machine Learning 2025<br> 
 <a href="https://arxiv.org/abs/2501.11739">Paper</a></dt>

<br>



<dt><i>Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience</i><br />Leonard B&auml;rmann, Chad DeChant, Joana Plewnia, Fabian Peller-Konrad, Daniel Bauer, Tamim Asfour, and Alex Waibel
<br>Humanoids conference 2025<br> <a href="https://arxiv.org/pdf/2409.17702">Paper</a> </dt>


<br>


    <dt><i>In search of the embgram: forming episodic representations in a deep learning model</i><br />Chad DeChant, Iretiayo Akinola, and Daniel Bauer
    <br>Cognitive Computational Neuroscience 2024 <br> <a href="https://2024.ccneuro.org/pdf/141_Paper_authored_CCN_2024_submission_with_names.pdf">Paper</a> </dt>



    <br>
    
    <dt><i>Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions</i><br />Chad DeChant, Iretiayo Akinola, and Daniel Bauer
    <br>Autonomous Robots <a href="https://link.springer.com/collections/bejhchcbag">Special issue on LLMs and Robotics</a>, November 2023
    <br>  <a href="https://link.springer.com/article/10.1007/s10514-023-10134-4">Paper</a> <a href="https://github.com/chaddech/roboreport/tree/main">Code</a> </dt>

    <br>
    

    <dt><i>On the risks and benefits of episodic memory in AI agents</i><br />
    Chad DeChant
    <br>Safe and Trustworthy AI Workshop at ICLP 2023
    <br><a href="http://www.cs.columbia.edu/~dechant/safeaiworkshop2023.pdf"> Paper</a></dt>
    <br>



    <dt><i>Are robots stuck in time? Learning to represent actions in long horizon planning by learning to remember the past</i><br />
    Chad DeChant
    <br>Learning, Perception, and Abstraction for Long-Horizon Planning Workshop at the Conference on Robot Learning 2022

    <br> <a href="https://openreview.net/pdf?id=GN2gXty2RnR">Paper</a></dt>

    <br>

    <dt><i>RoboReport: Summarizing a virtual robot's past actions in natural language</i><br />Chad DeChant, Iretiayo Akinola, and Daniel Bauer
    <br>Language and Robot Learning Workshop at the Conference on Robot Learning 2022 (Spotlight talk)
    <br>  <a href="https://openreview.net/pdf?id=Jhy3MXVA7mX">Paper</a> </dt>

    <br>

    <dt><i>Do you see what I see? Using questions and answers to align representations of robotic actions</i><br />Chad DeChant, Iretiayo Akinola, and Daniel Bauer
    <br>Aligning Robot Representations with Humans Workshop at the Conference on Robot Learning 2022

<br> <a href="https://aligning-robot-human-representations.github.io/docs/camready_6.pdf">Paper</a></dt>

    <br>

    <dt><i>Toward robots that learn to summarize their actions in natural language: a set of tasks</i><br />Chad DeChant and Daniel Bauer<br>Conference on Robot Learning 2021
    <br>    <a href="https://openreview.net/pdf?id=n3AW_ISWCXf">Paper</a> and <a href="https://openreview.net/forum?id=n3AW_ISWCXf">OpenReview</a></dt> 

    <br>

    <dt><i>Learning word representations in a developmentally realistic order</i><br />Chad DeChant and Daniel Bauer<br>2021 <a href="http://www.cs.columbia.edu/~dechant/metaword_rep4nlp.pdf"> Paper</a></dt>
    <br>

    <dt><i>Predicting the accuracy of neural networks from final and intermediate layer outputs</i><br />Chad DeChant, Seungwook Han, and Hod Lipson<br />Identifying and Understanding Deep Learning Phenomena workshop at ICML 2019<br /><a href="https://openreview.net/pdf?id=H1xXwEB2h4">Paper </a> </dt>
    <br>

    <dt><i>Learning to make accuracy judgments from intermediate and final outputs of a neural network for a question answering task</i><br />Chad DeChant, Seungwook Han, and Hod Lipson<br>BlackboxNLP at ACL 2019 <br /></dt> 
    <br>


    <dt><i>Automated identification of northern leaf blight-infected maize plants from field imagery using deep learning</i><br />Chad DeChant, Tyr Wiesner-Hanks, Siyuan Chen, Ethan Stewart, Jason Yosinski, Michael Gore, Rebecca Nelson, and Hod Lipson<br />Phytopathology 2017<br /><a href="https://www.researchgate.net/publication/317959991_Automated_Identification_of_Northern_Leaf_Blight-Infected_Maize_Plants_from_Field_Imagery_Using_Deep_Learning"> Paper</a></dt>
    <br>

    <dt><i>Shape completion enabled robotic grasping</i><br />Jacob Varley, Chad DeChant, Adam Richardson, Joaqu&iacuten Ruales, Peter Allen<br />Intelligent Robots and Systems (IROS) 2017<br /><a href="https://arxiv.org/pdf/1609.08546"> Paper</a> <a href="https://www.youtube.com/watch?v=Dxd0ItPhh7c"> Video</a></dt>
    <br>


  </dl>
  </ul>

    <H3>Other Publications</H3>
    <ul>
  <dl>


    <dt><i>Creating a Tool to Reproducibly Estimate the Ethical Impact of Artificial Intelligence</i><br />Sara Jordan, Sina Fazelpour, Adriano Koshiyama, Jaky Kueper, Chad DeChant, Brenda Leong, Gary Marchant, Craig Shank<br /><a href="https://escholarship.org/uc/item/56w756v8"> Paper</a> 2019</dt> 
    <br> 

    <dt><i>Could AI Drive Transformative Social Progress? What Would This Require?</i><br />Ted A Parson, Robert Lempert, Ben Armstrong, Evan Crothers, Chad DeChant, Nicholas Novelli<br /><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3476404"> Paper</a> 2019</dt>
    <br>

    <dt><i>*What can Natural Language Processing learn from the brain?</i><br>Intended as a quick guide to the brain's processing of language for NLP researchers along with some of my ideas for how such a perspective might influence future NLP research. Originally a paper and annotated bibliography I wrote for a class called Computation and the Brain, it needs more work. <br />Chad DeChant<br /><a href="http://www.cs.columbia.edu/~dechant/dechant_final_paper.pdf">DRAFT Paper </a> 2018</dt>  *in progress
    <br> 
    <br>
    <dt><i>AI, modularity, and the global workspace</i><br>Suggestions for applying ideas of modularity and the global workspace to AI. Written for a Psychology seminar.<br />Chad DeChant<br /><a href="http://www.cs.columbia.edu/~dechant/AI_modularity_global_workspace.pdf">Paper </a> 2017</dt> 
    <br> 


    <dt><i>Autonomous Detection of Plant Disease Symptoms Directly from Aerial Imagery</i><br />Harvey Wu, Tyr Wiesner-Hanks, Ethan L Stewart, Chad DeChant, Nicholas Kaczmar, Michael A Gore, Rebecca J Nelson, Hod Lipson<br />The Plant Phenome Journal 2019<br /><a href="https://dl.sciencesocieties.org/publications/tppj/abstracts/2/1/190006"> Paper</a></dt>
    <br>
    <dt><i>Quantitative Phenotyping of Northern Leaf Blight in UAV Images Using Deep Learning</i><br />Ethan L Stewart, Tyr Wiesner-Hanks, Nicholas Kaczmar, Chad DeChant, Harvey Wu, Hod Lipson, Rebecca J Nelson, Michael A Gore<br />Remote Sensing 2019<br /><a href="https://www.mdpi.com/2072-4292/11/19/2209"> Paper</a></dt>
    <br>

    <dt><i>Millimeter-level plant disease detection from aerial photographs via deep learning and crowdsourced data</i><br />Tyr Wiesner-Hanks, Harvey Wu, Ethan Stewart, Chad DeChant, Nicholas Kaczmar, Hod Lipson, Michael A Gore, Rebecca J Nelson<br />Frontiers in Plant Science 2019<br /><a href="https://www.researchgate.net/profile/Michael_Gore/publication/337909423_Millimeter-Level_Plant_Disease_Detection_From_Aerial_Photographs_via_Deep_Learning_and_Crowdsourced_Data/links/5df2d119299bf10bc3573303/Millimeter-Level-Plant-Disease-Detection-From-Aerial-Photographs-via-Deep-Learning-and-Crowdsourced-Data.pdf"> Paper</a></dt>
    <br>


    <dt><i>Image set for deep learning: field images of maize annotated with disease symptoms</i><br />Tyr Wiesner-Hanks, Ethan Stewart, Nicholas Kaczmar, Chad DeChant, Harvey Wu, Rebecca Nelson, Hod Lipson, and Michael Gore<br />BMC Research Notes 2018<br /><a href="https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-018-3548-6"> Paper</a></dt>
    <br>
    <dt><i>Automated Weed Detection in Aerial Imagery with Context</i><br />Delia Bullock, Andrew Mangeni, Tyr Wiesner-Hanks, Chad DeChant, Ethan L Stewart, Nicholas Kaczmar, Rebecca J Nelson, Michael A Gore, Hod Lipson<br /><a href="https://arxiv.org/abs/1910.00652"> Paper</a> 2019</dt> 
    <br>

<p>&nbsp;</p>
  </dl>

  <br>
</ul>
</div>



  <div id="index">
  <h3>Teaching</h3>
  <ul>
    <a href="aisafety18/">
      AI Safety, Ethics, and Policy
    </a>
    <br />I created and taught this course for Columbia undergraduates.
<br>
<br>

    <a href="http://llcao.net/cu-deeplearning17/index.html">
      Deep Learning for Computer Vision, Speech, and Language </a>
      <br />I served as a TA for this course after taking it. 



  </ul>
  <br>

  <h3>Other News</h3>
  <ul>



        I received a grant from the Long Term Future Fund in Spring 2022.<br>
<br>


        My thesis proposal was approved in December 2021.<br>
<br>

    In the Fall of 2020 I passed my candidacy exam on grounded language learning and meta learning.<br>
    <br>


    In the summer of 2019 I was chosen to participate (expenses paid) in the first <a href="https://www.amii.ca/summer-institute-on-ai-societal-impacts-governance-and-ethics-july-22-24-2019/"> Summer Institute on AI and Society </a> cosponsored by CIFAR, AMII, and UCLA Law School.<br>
  <br>
    <a href="https://magazine.engineering.columbia.edu/fall-2019/data-driven-ethics">An article</a> in Columbia Engineering magazine discusses my AI Safety, Ethics, and Policy class.<br>
  <br>
    I gave a <a href="https://vimeo.com/245017371">very short talk</a> at the Columbia Robotics Showcase on our work detecting plant disease using drones.

  </ul>
  <br>


    <h3>Volunteering</h3>
  <ul>

    I founded <a href="https://villagezendo.org/sanghas-supporting-refugees/">Sanghas Supporting Refugees</a> to support newly arrived refugees in New York City. The Associated Press mentioned our work <a href=https://apnews.com/article/russia-ukraine-immigration-europe-san-diego-religion-6435e3832c4753678f670b0ed81b6b5c>here</a>.
  </ul>

  <br>

  
    </ul>


  <br>
  <h3>Resources</h3>
  <ul>

  <a href="aisafety18/resources.html">AI Safety, Ethics, and Policy Resources</a>
  <br>

  <a href=deeplearning.html>Resources for learning Deep Learning</a>

    </ul>

<br>


  </div>

<div id="epilogue">
<br>
<hr>
<br>

</BODY>

</HTML>

