<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chad DeChant</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header>
            <div class="profile-photo">
                <img src="IMG_0104.jpg" alt="Chad DeChant">
            </div>
            <div class="header-info">
                <h1>Chad DeChant</h1>
                <div class="contact-info">
                    <p>chad.dechant@columbia.edu</p>
                </div>
                <div class="links">
                    <a href="https://twitter.com/chaddechant">Twitter</a>
                    <a href="https://scholar.google.com/citations?user=vZbAfPIAAAAJ&hl=en">Google Scholar</a>
                </div>
                <div class="education">
                    <p><strong>PhD, Computer Science</strong> - Columbia University</p>
                    <p><strong>MA, Government</strong> - Georgetown University</p>
                    <p><strong>BA, Philosophy</strong> - Georgetown University</p>
                </div>
            </div>
        </header>

        <section class="about">
            <h2>About</h2>
            <p>I received a PhD in Computer Science from Columbia in Spring 2025, advised by Daniel Bauer. My goal is to apply cognitive science research to make AI safe, reliable, and interpretable.</p>
            <p>My dissertation was on enabling robots to remember and report on their past actions in natural language through summaries and question answering. I believe that this ability is an essential one both for training robots and other agents to better understand their environments and for ensuring safe and understandable agent behavior.</p>
            <p>I have also worked on artificial metacognition (i.e. thinking about thinking, especially knowing what we know), learning word representations in the order a child learns words, improving robotic grasping techniques by learning to 'imagine' parts of objects that are hidden, and detecting crop disease from field imagery.</p>
            <p>I created and taught a course for Columbia undergraduates on AI Safety, Ethics, and Policy.</p>
            <div class="job-market">I am on the job market, looking for postdoc or research scientist positions.</div>
        </section>

        <section class="publications">
            <h2>Selected Publications</h2>

            <div class="publication">
                <div class="title">Episodic memory in AI agents poses risks that should be studied and mitigated</div>
                <div class="authors">Chad DeChant</div>
                <div class="venue">Conference on Secure and Trustworthy Machine Learning 2025</div>
                <div class="links"><a href="https://arxiv.org/abs/2501.11739">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience</div>
                <div class="authors">Leonard B&auml;rmann, Chad DeChant, Joana Plewnia, Fabian Peller-Konrad, Daniel Bauer, Tamim Asfour, and Alex Waibel</div>
                <div class="venue">Humanoids 2025</div>
                <div class="links"><a href="https://arxiv.org/pdf/2409.17702">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">In search of the embgram: forming episodic representations in a deep learning model</div>
                <div class="authors">Chad DeChant, Iretiayo Akinola, and Daniel Bauer</div>
                <div class="venue">Cognitive Computational Neuroscience 2024</div>
                <div class="links"><a href="https://2024.ccneuro.org/pdf/141_Paper_authored_CCN_2024_submission_with_names.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions</div>
                <div class="authors">Chad DeChant, Iretiayo Akinola, and Daniel Bauer</div>
                <div class="venue">Autonomous Robots, <a href="https://link.springer.com/collections/bejhchcbag">Special issue on LLMs and Robotics</a>, November 2023</div>
                <div class="links">
                    <a href="https://link.springer.com/article/10.1007/s10514-023-10134-4">Paper</a>
                    <a href="https://github.com/chaddech/roboreport/tree/main">Code</a>
                </div>
            </div>

            <div class="publication">
                <div class="title">On the risks and benefits of episodic memory in AI agents</div>
                <div class="authors">Chad DeChant</div>
                <div class="venue">Safe and Trustworthy AI Workshop at ICLP 2023</div>
                <div class="links"><a href="http://www.cs.columbia.edu/~dechant/safeaiworkshop2023.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Are robots stuck in time? Learning to represent actions in long horizon planning by learning to remember the past</div>
                <div class="authors">Chad DeChant</div>
                <div class="venue">Learning, Perception, and Abstraction for Long-Horizon Planning Workshop at CoRL 2022</div>
                <div class="links"><a href="https://openreview.net/pdf?id=GN2gXty2RnR">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">RoboReport: Summarizing a virtual robot's past actions in natural language</div>
                <div class="authors">Chad DeChant, Iretiayo Akinola, and Daniel Bauer</div>
                <div class="venue">Language and Robot Learning Workshop at CoRL 2022 (Spotlight talk)</div>
                <div class="links"><a href="https://openreview.net/pdf?id=Jhy3MXVA7mX">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Do you see what I see? Using questions and answers to align representations of robotic actions</div>
                <div class="authors">Chad DeChant, Iretiayo Akinola, and Daniel Bauer</div>
                <div class="venue">Aligning Robot Representations with Humans Workshop at CoRL 2022</div>
                <div class="links"><a href="https://aligning-robot-human-representations.github.io/docs/camready_6.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Toward robots that learn to summarize their actions in natural language: a set of tasks</div>
                <div class="authors">Chad DeChant and Daniel Bauer</div>
                <div class="venue">Conference on Robot Learning 2021</div>
                <div class="links">
                    <a href="https://openreview.net/pdf?id=n3AW_ISWCXf">Paper</a>
                    <a href="https://openreview.net/forum?id=n3AW_ISWCXf">OpenReview</a>
                </div>
            </div>

            <div class="publication">
                <div class="title">Learning word representations in a developmentally realistic order</div>
                <div class="authors">Chad DeChant and Daniel Bauer</div>
                <div class="venue">2021</div>
                <div class="links"><a href="http://www.cs.columbia.edu/~dechant/metaword_rep4nlp.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Predicting the accuracy of neural networks from final and intermediate layer outputs</div>
                <div class="authors">Chad DeChant, Seungwook Han, and Hod Lipson</div>
                <div class="venue">Identifying and Understanding Deep Learning Phenomena workshop at ICML 2019</div>
                <div class="links"><a href="https://openreview.net/pdf?id=H1xXwEB2h4">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Learning to make accuracy judgments from intermediate and final outputs of a neural network for a question answering task</div>
                <div class="authors">Chad DeChant, Seungwook Han, and Hod Lipson</div>
                <div class="venue">BlackboxNLP at ACL 2019</div>
            </div>

            <div class="publication">
                <div class="title">Automated identification of northern leaf blight-infected maize plants from field imagery using deep learning</div>
                <div class="authors">Chad DeChant, Tyr Wiesner-Hanks, Siyuan Chen, Ethan Stewart, Jason Yosinski, Michael Gore, Rebecca Nelson, and Hod Lipson</div>
                <div class="venue">Phytopathology 2017</div>
                <div class="links"><a href="https://www.researchgate.net/publication/317959991_Automated_Identification_of_Northern_Leaf_Blight-Infected_Maize_Plants_from_Field_Imagery_Using_Deep_Learning">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Shape completion enabled robotic grasping</div>
                <div class="authors">Jacob Varley, Chad DeChant, Adam Richardson, Joaqu&iacute;n Ruales, Peter Allen</div>
                <div class="venue">Intelligent Robots and Systems (IROS) 2017</div>
                <div class="links">
                    <a href="https://arxiv.org/pdf/1609.08546">Paper</a>
                    <a href="https://www.youtube.com/watch?v=Dxd0ItPhh7c">Video</a>
                </div>
            </div>

            <h3>Other Publications</h3>

            <div class="publication">
                <div class="title">Creating a Tool to Reproducibly Estimate the Ethical Impact of Artificial Intelligence</div>
                <div class="authors">Sara Jordan, Sina Fazelpour, Adriano Koshiyama, Jaky Kueper, Chad DeChant, Brenda Leong, Gary Marchant, Craig Shank</div>
                <div class="venue">2019</div>
                <div class="links"><a href="https://escholarship.org/uc/item/56w756v8">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Could AI Drive Transformative Social Progress? What Would This Require?</div>
                <div class="authors">Ted A Parson, Robert Lempert, Ben Armstrong, Evan Crothers, Chad DeChant, Nicholas Novelli</div>
                <div class="venue">2019</div>
                <div class="links"><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3476404">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">What can Natural Language Processing learn from the brain? (Draft)</div>
                <div class="authors">Chad DeChant</div>
                <div class="venue">2018</div>
                <div class="links"><a href="http://www.cs.columbia.edu/~dechant/dechant_final_paper.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">AI, modularity, and the global workspace</div>
                <div class="authors">Chad DeChant</div>
                <div class="venue">2017</div>
                <div class="links"><a href="http://www.cs.columbia.edu/~dechant/AI_modularity_global_workspace.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Autonomous Detection of Plant Disease Symptoms Directly from Aerial Imagery</div>
                <div class="authors">Harvey Wu, Tyr Wiesner-Hanks, Ethan L Stewart, Chad DeChant, Nicholas Kaczmar, Michael A Gore, Rebecca J Nelson, Hod Lipson</div>
                <div class="venue">The Plant Phenome Journal 2019</div>
                <div class="links"><a href="https://dl.sciencesocieties.org/publications/tppj/abstracts/2/1/190006">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Quantitative Phenotyping of Northern Leaf Blight in UAV Images Using Deep Learning</div>
                <div class="authors">Ethan L Stewart, Tyr Wiesner-Hanks, Nicholas Kaczmar, Chad DeChant, Harvey Wu, Hod Lipson, Rebecca J Nelson, Michael A Gore</div>
                <div class="venue">Remote Sensing 2019</div>
                <div class="links"><a href="https://www.mdpi.com/2072-4292/11/19/2209">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Millimeter-level plant disease detection from aerial photographs via deep learning and crowdsourced data</div>
                <div class="authors">Tyr Wiesner-Hanks, Harvey Wu, Ethan Stewart, Chad DeChant, Nicholas Kaczmar, Hod Lipson, Michael A Gore, Rebecca J Nelson</div>
                <div class="venue">Frontiers in Plant Science 2019</div>
                <div class="links"><a href="https://www.researchgate.net/profile/Michael_Gore/publication/337909423_Millimeter-Level_Plant_Disease_Detection_From_Aerial_Photographs_via_Deep_Learning_and_Crowdsourced_Data/links/5df2d119299bf10bc3573303/Millimeter-Level-Plant-Disease-Detection-From-Aerial-Photographs-via-Deep-Learning-and-Crowdsourced-Data.pdf">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Image set for deep learning: field images of maize annotated with disease symptoms</div>
                <div class="authors">Tyr Wiesner-Hanks, Ethan Stewart, Nicholas Kaczmar, Chad DeChant, Harvey Wu, Rebecca Nelson, Hod Lipson, and Michael Gore</div>
                <div class="venue">BMC Research Notes 2018</div>
                <div class="links"><a href="https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-018-3548-6">Paper</a></div>
            </div>

            <div class="publication">
                <div class="title">Automated Weed Detection in Aerial Imagery with Context</div>
                <div class="authors">Delia Bullock, Andrew Mangeni, Tyr Wiesner-Hanks, Chad DeChant, Ethan L Stewart, Nicholas Kaczmar, Rebecca J Nelson, Michael A Gore, Hod Lipson</div>
                <div class="venue">2019</div>
                <div class="links"><a href="https://arxiv.org/abs/1910.00652">Paper</a></div>
            </div>
        </section>

        <section class="teaching">
            <h2>Teaching</h2>
            <div class="teaching-item">
                <a href="aisafety18/">AI Safety, Ethics, and Policy</a>
                <p>I created and taught this course for Columbia undergraduates.</p>
            </div>
            <div class="teaching-item">
                <a href="http://llcao.net/cu-deeplearning17/index.html">Deep Learning for Computer Vision, Speech, and Language</a>
                <p>I served as a TA for this course after taking it.</p>
            </div>
        </section>

        <section class="news">
            <h2>News</h2>
            <div class="news-item">I received a grant from the Long Term Future Fund in Spring 2022.</div>
            <div class="news-item">My thesis proposal was approved in December 2021.</div>
            <div class="news-item">In the Fall of 2020 I passed my candidacy exam on grounded language learning and meta learning.</div>
            <div class="news-item">In the summer of 2019 I was chosen to participate (expenses paid) in the first <a href="https://www.amii.ca/summer-institute-on-ai-societal-impacts-governance-and-ethics-july-22-24-2019/">Summer Institute on AI and Society</a> cosponsored by CIFAR, AMII, and UCLA Law School.</div>
            <div class="news-item"><a href="https://magazine.engineering.columbia.edu/fall-2019/data-driven-ethics">An article</a> in Columbia Engineering magazine discusses my AI Safety, Ethics, and Policy class.</div>
            <div class="news-item">I gave a <a href="https://vimeo.com/245017371">very short talk</a> at the Columbia Robotics Showcase on our work detecting plant disease using drones.</div>
        </section>

        <section class="volunteering">
            <h2>Volunteering</h2>
            <p>I founded <a href="https://villagezendo.org/sanghas-supporting-refugees/">Sanghas Supporting Refugees</a> to support newly arrived refugees in New York City. The Associated Press mentioned our work <a href="https://apnews.com/article/russia-ukraine-immigration-europe-san-diego-religion-6435e3832c4753678f670b0ed81b6b5c">here</a>.</p>
        </section>

        <section class="resources">
            <h2>Resources</h2>
            <ul>
                <li><a href="aisafety18/resources.html">AI Safety, Ethics, and Policy Resources</a></li>
                <li><a href="deeplearning.html">Resources for learning Deep Learning</a></li>
            </ul>
        </section>

        <footer>
            <p>Chad DeChant</p>
        </footer>
    </div>
</body>
</html>
